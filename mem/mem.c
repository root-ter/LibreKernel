#include "mem.h"
#include "../spinlock/spinlock.h"
#include "../lib/string.h"
#include <stdint.h>
#include <stddef.h>

static spinlock_t malloc_lock = SPINLOCK_INIT;

/* Конфигурация */
#define ALIGN 8
#define MAGIC 0xB16B00B5U

/* Заголовок блока (payload идёт сразу после заголовка) */
typedef struct block_header
{
    uint32_t magic;
    size_t size; /* payload size в байтах */
    int free;    /* 1 если свободен, 0 если занят */
    struct block_header *prev;
    struct block_header *next;
} block_header_t;

#define MIN_SPLIT_SIZE (sizeof(block_header_t) + ALIGN)

/* Глобальные */
static block_header_t *heap_head = NULL;
static block_header_t *heap_tail = NULL;
static void *managed_heap_end = NULL;
static unsigned char *brk_ptr = NULL; /* текущий предел (bump pointer внутри области) */

/* Символы из link.ld */
extern char _heap_start;
extern char _heap_end;

/* Внешние функции (реализованы в других файлах вашего ядра) */
extern void *memcpy(void *dst, const void *src, size_t n);

static inline size_t align_up(size_t n)
{
    return (n + (ALIGN - 1)) & ~(ALIGN - 1);
}
static inline void *header_to_payload(block_header_t *h)
{
    return (void *)((char *)h + sizeof(block_header_t));
}
static inline block_header_t *payload_to_header(void *p)
{
    return (block_header_t *)((char *)p - sizeof(block_header_t));
}

/* Инициализация: передайте _heap_start и размер (в байтах) */
void malloc_init(void *heap_start, size_t heap_size)
{
	spin_lock(&malloc_lock);
	
    if (!heap_start || heap_size < sizeof(block_header_t)) {
    	spin_unlock(&malloc_lock);
        return;
    }
    
    heap_head = (block_header_t *)heap_start;
    heap_head->magic = MAGIC;
    heap_head->size = heap_size - sizeof(block_header_t);
    heap_head->free = 1;
    heap_head->prev = heap_head->next = NULL;

    heap_tail = heap_head;
    managed_heap_end = (char *)heap_start + heap_size;
    brk_ptr = (unsigned char *)heap_start + heap_size; /* brk_ptr хранит верх резервируемой области */
    spin_unlock(&malloc_lock);
}

/* Вспомогательная: выделить память у движка morecore (bump) — без привязки к page allocator.
   Возвращает pointer на область размера >= bytes (включая заголовок), или NULL при исчерпании.
   Мы выделяем сверху вниз: brk_ptr двигается вниз при выделении. */
static void *simple_morecore(size_t bytes)
{
    /* Выравниваем bytes вверх */
    size_t req = align_up(bytes);

    unsigned char *new_brk = (unsigned char *)brk_ptr - req;
    if ((void *)new_brk < (void *)&_heap_start)
    {
        /* исчерпали область */
        return NULL;
    }

    brk_ptr = new_brk;
    return (void *)brk_ptr;
}

/* find first-fit */
static block_header_t *find_fit(size_t size)
{
    block_header_t *cur = heap_head;
    while (cur)
    {
        if (cur->free && cur->size >= size)
            return cur;
        cur = cur->next;
    }
    return NULL;
}

/* split блока */
static void split_block(block_header_t *h, size_t req_size)
{
    if (!h)
        return;
    if (h->size < req_size + MIN_SPLIT_SIZE)
        return;

    char *new_hdr_addr = (char *)header_to_payload(h) + req_size;
    block_header_t *newh = (block_header_t *)new_hdr_addr;
    newh->magic = MAGIC;
    newh->free = 1;
    newh->size = h->size - req_size - sizeof(block_header_t);
    newh->prev = h;
    newh->next = h->next;
    if (newh->next)
        newh->next->prev = newh;
    h->next = newh;
    h->size = req_size;
    if (heap_tail == h)
        heap_tail = newh;
}

/* coalesce */
static void coalesce(block_header_t *h)
{
    if (!h)
        return;
    if (h->next && h->next->free)
    {
        block_header_t *n = h->next;
        h->size = h->size + sizeof(block_header_t) + n->size;
        h->next = n->next;
        if (n->next)
            n->next->prev = h;
        if (heap_tail == n)
            heap_tail = h;
    }
    if (h->prev && h->prev->free)
    {
        block_header_t *p = h->prev;
        p->size = p->size + sizeof(block_header_t) + h->size;
        p->next = h->next;
        if (h->next)
            h->next->prev = p;
        if (heap_tail == h)
            heap_tail = p;
        h = p;
    }
}

/* попытка расширить heap: создаём новый блок в свободной области сверху (через simple_morecore)
   запрашивая минимум bytes + sizeof(block_header_t) */
static int heap_expand(size_t bytes)
{
    size_t need = align_up(bytes + sizeof(block_header_t));
    void *p = simple_morecore(need);
    if (!p)
        return 0;

    block_header_t *h = (block_header_t *)p;
    h->magic = MAGIC;
    h->free = 1;
    h->size = need - sizeof(block_header_t);
    h->prev = heap_tail;
    h->next = NULL;
    if (heap_tail)
        heap_tail->next = h;
    heap_tail = h;
    if (!heap_head)
        heap_head = h;
    return 1;
}

/* malloc */
void *malloc(size_t size)
{
    if (size == 0)
        return NULL;
    size = align_up(size);
    
    spin_lock(&malloc_lock);

    block_header_t *fit = find_fit(size);
    while (!fit)
    {
        if (!heap_expand(size))
            break;
        fit = find_fit(size);
    }
    if (!fit) {
    	spin_unlock(&malloc_lock);
        return NULL;
    }
    split_block(fit, size);
    fit->free = 0;
    spin_unlock(&malloc_lock);
    return header_to_payload(fit);
}

/* free */
void free(void *ptr)
{
    if (!ptr)
        return;
    
    spin_lock(&malloc_lock);

    block_header_t *h = payload_to_header(ptr);

    /* проверяем magic */
    if (h->magic != MAGIC) {
    	spin_unlock(&malloc_lock);
        return; /* повреждённый или неверный указатель */
    }

    /* проверка на многократное освобождение */
    if (h->free) {
    	spin_unlock(&malloc_lock);
        return; /* уже свободен, ничего не делаем */
    }

    h->free = 1;

    /* объединяем соседние свободные блоки */
    coalesce(h);
    
    spin_unlock(&malloc_lock);
}

/* realloc */
void *realloc(void *ptr, size_t new_size)
{
    if (!ptr)
        return malloc(new_size);
    if (new_size == 0)
    {
        free(ptr);
        return NULL;
    }
    
    spin_lock(&malloc_lock);

    block_header_t *h = payload_to_header(ptr);
    if (h->magic != MAGIC) {
    	spin_unlock(&malloc_lock);
        return NULL;
    }

    new_size = align_up(new_size);
    
    if (new_size <= h->size)
    {
        split_block(h, new_size);
        spin_unlock(&malloc_lock);
        return ptr;
    }

    /* Попытка расширить in-place за счёт следующего свободного блока(ов) */
    if (h->next && h->next->free)
    {
        size_t sum = h->size;
        block_header_t *cur = h->next;
        while (cur && cur->free && sum < new_size)
        {
            sum += sizeof(block_header_t) + cur->size;
            cur = cur->next;
        }
        if (sum >= new_size)
        {
            /* объединяем до cur_prev */
            block_header_t *to = h->next;
            while (to && to->free && h->size < new_size)
            {
                h->size = h->size + sizeof(block_header_t) + to->size;
                to = to->next;
            }
            h->next = to;
            if (to)
                to->prev = h;
            split_block(h, new_size);
            h->free = 0;
            spin_unlock(&malloc_lock);
            return ptr;
        }
    }

    /* Нельзя in-place — выделяем новый, копируем и освобождаем старый */
    void *newp = malloc(new_size);
    if (!newp) {
    	spin_unlock(&malloc_lock);
        return NULL;
    }
    size_t copy = (h->size < new_size) ? h->size : new_size;
    memcpy(newp, ptr, copy);
    free(ptr);
    
    spin_unlock(&malloc_lock);
    return newp;
}
